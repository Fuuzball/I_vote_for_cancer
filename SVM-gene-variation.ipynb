{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import helpers\n",
    "\n",
    "%matplotlib inline\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, chi2, f_classif\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2656, 5)\n",
      "(665, 5)\n"
     ]
    }
   ],
   "source": [
    "text, variants = helpers.get_training('./input/training_variants', './input/training_text')\n",
    "#train_full, val_full = train_test_split(variants.merge(text, how='inner', on='ID'))\n",
    "train_full = variants.merge(text, how='inner', on='ID')\n",
    "\n",
    "#this is 20% of the labeled data\n",
    "text, variants = helpers.get_test('./input/training_variants', './input/training_text')\n",
    "test_full = variants.merge(text, how='inner', on='ID')\n",
    "\n",
    "print(train_full.shape)\n",
    "#print(val_full.shape)\n",
    "print(test_full.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use TF-IDF to Vectorize the textsï¼Œ a feature selector, then SVM one-vs-all classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "##Pipeline\n",
    "tfidf = TfidfVectorizer(\n",
    "    min_df=1, max_features=16000, strip_accents='unicode',lowercase =True,\n",
    "    analyzer='word', use_idf=True, \n",
    "    smooth_idf=True, sublinear_tf=True, stop_words = 'english')\n",
    "ffilter = SelectKBest(mutual_info_classif, k=500)\n",
    "#ffilter = SelectKBest(chi2, k=500)\n",
    "#ffilter = SelectKBest(f_classif, k=500)\n",
    "#ffilter = TruncatedSVD(n_components=100)\n",
    "#ffilter = LinearDiscriminantAnalysis(n_components=100)\n",
    "\n",
    "##Data and labels\n",
    "y_train = train_full[\"Class\"]-1\n",
    "X_train = ffilter.fit_transform(tfidf.fit_transform(train_full[\"Text\"]), y_train)\n",
    "\n",
    "#y_val = val_full[\"Class\"]-1\n",
    "#X_val = ffilter.transform(tfidf.transform(val_full[\"Text\"]))\n",
    "\n",
    "y_test = test_full[\"Class\"]-1\n",
    "X_test = ffilter.transform(tfidf.transform(test_full[\"Text\"]))\n",
    "\n",
    "y_train_bi = label_binarize(y_train, classes=range(9))\n",
    "#y_val_bi = label_binarize(y_val, classes=range(9))\n",
    "y_test_bi = label_binarize(y_test, classes=range(9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=OneVsRestClassifier(estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          n_jobs=1),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'estimator__C': [10], 'estimator__kernel': ['linear']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_log_loss', verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Fitting\n",
    "parameters = {\n",
    "    \"estimator__C\": [10],\n",
    "    \"estimator__kernel\": ['linear']\n",
    "    #\"estimator__degree\": [2, 3]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(OneVsRestClassifier(svm.SVC(probability=True, class_weight='balanced')), param_grid=parameters, scoring='neg_log_loss', n_jobs=-1)\n",
    "clf.fit(X_train, y_train_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Evaluate\n",
    "print(log_loss(y_train, clf.predict_proba(X_train), eps=1e-15, normalize=True, labels=range(9)))\n",
    "#print(log_loss(y_val, clf.predict_proba(X_val), eps=1e-15, normalize=True, labels=range(9)))\n",
    "print(log_loss(y_test, clf.predict_proba(X_test), eps=1e-15, normalize=True, labels=range(9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "helpers.plot_roc_curve(y_test_bi, y_test_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "X_submit = ffilter.transform(tfidf.transform(\\\n",
    "    pd.read_csv('./data/test_text', sep=\"\\|\\|\", engine=\"python\", skiprows=1, names=[\"ID\", \"Text\"])[\"Text\"]))\n",
    "\n",
    "y_submit_prob = clf.predict_proba(X_submit) \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./data/submission.csv', 'w') as f:\n",
    "    f.write('ID,class1,class2,class3,class4,class5,class6,class7,class8,class9\\n')\n",
    "    for i in range(y_submit_prob.shape[0]):\n",
    "        f.write(str(i)+',')\n",
    "        for j in range(y_submit_prob.shape[1]):\n",
    "            f.write(str(y_submit_prob[i][j]))\n",
    "            if j<8:\n",
    "                f.write(',')\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtr_test = tfidf.transform(X_test)\n",
    "\n",
    "X_train_tfidf = np.array(ffilter.transform(Xtr_train).todense())\n",
    "X_test_tfidf = np.array(ffilter.transform(Xtr_test).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('./data/X_train_tfidf', X_train_tfidf)\n",
    "np.save('./data/X_test_tfidf', X_test_tfidf)\n",
    "np.save('./data/y_train_tfidf', y_train_bi)\n",
    "np.save('./data/y_test_tfidf', y_test_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:cancer]",
   "language": "python",
   "name": "conda-env-cancer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
