{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import helpers\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from w2v import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,y_train = helpers.get_1st_layer_data('./data/training_variants', './data/training_text')\n",
    "X_val,y_val = helpers.get_2nd_layer_data('./data/training_variants', './data/training_text')\n",
    "\n",
    "X_train = X_train.Text\n",
    "y_train = y_train.Class\n",
    "X_val = X_val.Text\n",
    "y_val = y_val.Class\n",
    "\n",
    "y_train = onehot(y_train)\n",
    "y_val = onehot(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v = W2vVectorizer(100)\n",
    "w2v.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "Xtr = w2v.vectorize_documents(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idx = w2v.tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = w2v.tfidf.vocabulary_['the']\n",
    "w2v.tfidf.idf_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.58465809643\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "X = c.X_train\n",
    "clf = OneVsRestClassifier(svm.SVC(C=1.0, kernel='linear', probability=True,\n",
    "                                 random_state=0, class_weight='balanced'))\n",
    "y_train_bi = c.onehot(y_train)\n",
    "clf.fit(X, y_train_bi)\n",
    "y_train_prob = clf.predict_proba(X)\n",
    "for i in range(y_train_prob.shape[0]):\n",
    "    y_train_prob[i] = y_train_prob[i]/np.sum(y_train_prob[i])\n",
    "print(c.logloss(y_train, y_train_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0984012916924817"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_train_bi, y_train_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val,y_val = helpers.get_2nd_layer_data('./data/training_variants', './data/training_text')\n",
    "X_val = X_val.Text\n",
    "y_val = y_val.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "Xval = c.vectorize_documents(X_val, tfidf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3088687702835973"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_bi = c.onehot(y_val)\n",
    "y_val_prob = clf.predict_proba(Xval)\n",
    "for i in range(y_val_prob.shape[0]):\n",
    "    y_val_prob[i] = y_val_prob[i]/np.sum(y_val_prob[i])\n",
    "log_loss(y_val_bi, y_val_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.94022067452\n"
     ]
    }
   ],
   "source": [
    "import sklearn.decomposition as dcmp\n",
    "pca = dcmp.PCA(n_components=20)\n",
    "pca.fit(X)\n",
    "Xreduced = pca.transform(X)\n",
    "\n",
    "clf = OneVsRestClassifier(svm.SVC(C=1.0, kernel='linear', probability=True,\n",
    "                                 random_state=0, class_weight='balanced'))\n",
    "y_train_bi = c.onehot(y_train)\n",
    "clf.fit(Xreduced, y_train_bi)\n",
    "y_train_prob = clf.predict_proba(Xreduced)\n",
    "for i in range(y_train_prob.shape[0]):\n",
    "    y_train_prob[i] = y_train_prob[i]/np.sum(y_train_prob[i])\n",
    "print(c.logloss(y_train, y_train_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "clf_notf = W2vClassifier(w2v)\n",
    "clf_notf.fit(X_train, y_train, tfidf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.19244342, -3.0563039 , -3.20778469, -3.10776285, -3.50422472,\n",
       "       -3.64655801, -2.94548018, -3.02393552, -2.99516079])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_notf = clf_notf.X_train\n",
    "p_notf = clf_notf.predict(X_notf)\n",
    "clf_notf.logloss(y_train, p_notf)\n",
    "#p_notf[150,:]\n",
    "np.log2(p_notf[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X, ctr):\n",
    "    p = np.zeros((X.shape[0], 9))\n",
    "    for n in range(X.shape[0]):\n",
    "        d = np.zeros(9)\n",
    "        for i in range(9):\n",
    "            d[i] = np.linalg.norm(X[n,:] - ctr[i,:])\n",
    "        d = d/np.linalg.norm(d)\n",
    "        p[n,:] = d\n",
    "    return p\n",
    "\n",
    "def onehot(y):\n",
    "    output = np.zeros((len(y), 9))\n",
    "    for i,n in enumerate(y):\n",
    "        output[i,n-1]=1\n",
    "    return output\n",
    "\n",
    "def logloss(y, X):\n",
    "    N = X.shape[0]\n",
    "    x = 0\n",
    "    for i in range(N):\n",
    "        x+= np.dot(y[i,:], np.log2(X[i,:]))\n",
    "    x = (-1./N)*x\n",
    "    return x\n",
    "\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "c = NearestCentroid()\n",
    "c.fit(X, y_train)\n",
    "centroids = c.centroids_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.16672715,  0.25744363, -0.42377448,  0.26536373, -0.62897261,\n",
       "       -0.26353329,  0.80095657,  0.30173567,  0.13773757, -0.10799293,\n",
       "       -0.02260212,  1.24072738, -0.10159008,  0.38701266, -0.31329377,\n",
       "       -0.35711027,  0.77338455,  0.43810271,  0.73211481,  0.93856294,\n",
       "       -0.31030487,  1.11919873,  0.42846298,  0.2530371 , -0.6827164 ,\n",
       "       -0.08861157, -0.27281188,  0.60802126,  0.32148301, -0.46341217,\n",
       "       -0.19626264,  0.16682749,  0.98040099,  0.22487089,  0.6447319 ,\n",
       "       -0.16043369,  0.63235187, -0.15444313, -0.8693384 ,  0.44117362,\n",
       "       -0.72841232,  0.68456727, -0.55836042, -0.26147683,  0.84621823,\n",
       "       -0.8939317 ,  0.67219753,  1.11184505, -0.30801649,  0.89921412,\n",
       "       -1.44102145, -0.68769905, -0.48858732,  0.57803893, -1.17605869,\n",
       "        0.61256433, -1.16603563, -1.2269977 ,  0.35139778,  0.45409314,\n",
       "        0.47698525,  0.48804571, -0.16866079,  0.82144682,  1.57992544,\n",
       "        0.4030514 ,  1.06988247, -1.33053118,  0.02603815,  0.80791258,\n",
       "       -0.08805949, -0.32427162,  0.23326899,  0.32846146,  0.54232323,\n",
       "        1.67472165, -1.25724415,  0.87227228, -0.77438228, -0.07803803,\n",
       "        1.16773814, -1.09954591,  0.3209523 , -0.24171403,  0.45230224,\n",
       "       -0.82108593, -0.46902749, -0.07971298, -0.03587303,  0.08240322,\n",
       "        0.49390037, -0.16445396, -0.14072982, -1.90399024, -2.61049858,\n",
       "        0.23211717,  2.02562995,  1.36465018,  1.33019444, -0.03161422])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.doc2vec(X_train[2776], tfidf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -612.69074405,   884.63641779,   188.11441896,   869.4578879 ,\n",
       "         236.52169555,  1930.53849845,  -230.35156607, -1419.00583034,\n",
       "        1592.70161469,   283.66059029,  1400.6125453 ,  -159.68268552,\n",
       "         633.82045676,   630.56416987,   102.35052067, -1058.10049467,\n",
       "       -1049.82007331,   517.35671474,  1189.86829748,  1312.06203883,\n",
       "        1411.39229163, -1077.88805156,  1495.58262442,  -110.62999665,\n",
       "        1954.54638086, -1471.04007508,  -877.89515971,  -883.8967006 ,\n",
       "        1594.29385003, -1388.55178019, -1819.76945514, -1996.96231331,\n",
       "        1178.68351451,  -586.17481024,   718.02217615,  1503.85120194,\n",
       "        -933.34505058,  -406.76921999,   927.29724791,  -260.72548855,\n",
       "         674.75931309,  2606.6250046 , -2666.83298149,  1925.74971812,\n",
       "        1401.11069911,   542.41260616,  -755.90918895,  2642.80687458,\n",
       "        1384.4640621 ,    41.17923538, -1156.86364584,  2838.03249791,\n",
       "       -1211.97169885, -2999.68423994, -1427.26741994,  -123.61069282,\n",
       "        -110.23468949, -1364.45629524,   286.30751134, -2309.5819672 ,\n",
       "         850.07346301, -2325.56994165, -3244.39509123,   712.3685427 ,\n",
       "        2498.4398724 ,  -303.63038696, -2815.87635593, -1357.83872501,\n",
       "        -986.22317951, -1419.41396188, -1284.93683197, -2239.70135858,\n",
       "         277.74008833,  -316.02242976,  -670.99547526,   824.79163327,\n",
       "        1849.42899961,   193.0338318 ,  1486.67552312,  1684.55812869,\n",
       "       -1117.04487088,   733.83907651,  -175.10382092,  -723.3183584 ,\n",
       "        -273.61597165,  4282.23968378,  -735.09451131,   646.67329052,\n",
       "       -1974.78205158,   490.07988982, -1437.97866384, -1507.07938671,\n",
       "         -77.91617763,  -950.26878193,  -695.67696186,  -412.7625458 ,\n",
       "        -734.97186599,  -233.73661684,   877.43201335, -2028.72120309])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = w2v.tfidf\n",
    "\n",
    "#%timeit tfidf.idf_[tfidf.vocabulary_['brca1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.idf_[tfidf.vocabulary_['the']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254 µs ± 17 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit tfidf.idf_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5108256237659907"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.idf_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc = X_train[2776].lower()\n",
    "words = doc.split(' ')\n",
    "v = np.zeros(len(words), dtype=int)\n",
    "error_indices = np.ones_like(v)\n",
    "M = np.zeros((len(words), 100))\n",
    "for i, w in enumerate(words):\n",
    "    try:\n",
    "        v[i] = tfidf.vocabulary_[w]\n",
    "        M[i,:] = w2v.word2vec(w)\n",
    "    except:\n",
    "        error_indices[i] = 0\n",
    "weights = np.log(tfidf.idf_[v])*error_indices\n",
    "docvector = np.zeros_like(M[0,:])\n",
    "for i,w in enumerate(words):\n",
    "    docvector += weights[i]*M[i,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
