{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import helpers\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = helpers.train_test_split('./data/training_variants', './data/training_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will mostly follow examples from\n",
    "http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/\n",
    "and\n",
    "https://codesachin.wordpress.com/2015/10/09/generating-a-word2vec-model-from-a-block-of-text-using-gensim-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_text = X_train.Text.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_sentences(text):\n",
    "    sentences = []\n",
    "    for document in text:\n",
    "        sts = document.split('.') # list of sentences in the document\n",
    "        for s in sts:\n",
    "            sentences.append(s.split(' '))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build words from the unique text\n",
    "class sentences:\n",
    "    def __init__(self, txt):\n",
    "        self.n = len(txt)\n",
    "        self.i = 0\n",
    "        self.txt = txt\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self.i >= self.n:\n",
    "            raise StopIteration\n",
    "        self.i += 1\n",
    "        return self.txt[self.i-1].split(' ')\n",
    "k = build_sentences(unique_text[0:500])\n",
    "model = gensim.models.Word2Vec(k, size=100)\n",
    "#model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46584247226638104"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('tumor', 'cancer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2vec(doc):\n",
    "    words = doc.split(' ')\n",
    "    N = 0\n",
    "    v = np.zeros(100)\n",
    "    for w in words:\n",
    "        try:\n",
    "            v+=model[w.rstrip('.')]\n",
    "            N +=1\n",
    "        except KeyError:\n",
    "            pass\n",
    "    v = (1./N)*v\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -8.75072366e-01,   6.81262876e-01,   1.63646727e-01,\n",
       "        -6.62472303e-02,   3.16447992e-01,   3.17690920e-01,\n",
       "        -4.16821289e-01,  -1.26504012e-01,  -7.46390552e-01,\n",
       "         5.62878910e-01,  -1.25126667e+00,  -8.84982316e-01,\n",
       "        -1.41146815e-01,   3.55916664e-01,   6.89787582e-01,\n",
       "        -8.28153093e-01,   5.42554148e-01,   1.16406871e-01,\n",
       "         3.53334772e-01,   1.64851126e-01,   5.86909858e-02,\n",
       "        -1.44564929e-01,   3.05625681e-01,  -5.69258288e-01,\n",
       "        -5.41004969e-02,  -2.35740282e-01,   8.05800762e-02,\n",
       "        -5.51108543e-01,   6.38452994e-02,   4.60677014e-01,\n",
       "        -1.11976935e-01,  -3.28893528e-01,   4.52132536e-01,\n",
       "         5.00385182e-01,   1.18736550e-01,   3.50027780e-01,\n",
       "         3.53953641e-01,  -1.73438528e-01,  -3.40972794e-01,\n",
       "         1.64358929e-01,   2.68582777e-01,   2.17740401e-01,\n",
       "        -3.15967371e-01,   5.25950685e-02,   9.89642717e-01,\n",
       "        -1.39784870e-01,  -4.33217375e-01,   9.87710120e-05,\n",
       "        -2.68947544e-01,  -4.19169203e-01,   4.32220038e-01,\n",
       "         2.36490183e-01,  -2.31359098e-01,   2.94230223e-01,\n",
       "        -4.81775987e-01,   8.88376990e-01,   2.06634123e-01,\n",
       "         8.34375132e-01,  -4.98781239e-01,   8.45335621e-01,\n",
       "         3.37304589e-01,  -3.25935615e-01,  -3.14823913e-01,\n",
       "         3.55999711e-01,   4.50878854e-01,   2.09700465e-01,\n",
       "        -1.05914347e+00,  -7.20879660e-01,  -4.77372311e-01,\n",
       "         6.19665500e-01,  -7.66417860e-02,   3.94734973e-01,\n",
       "         1.18443435e-01,   3.15287057e-01,   4.58293146e-01,\n",
       "         8.86404174e-01,  -3.11202662e-02,   4.35599049e-01,\n",
       "         1.07282772e-01,   3.43353828e-01,   7.22704596e-02,\n",
       "        -4.00840410e-03,   3.00536241e-01,   7.78635599e-01,\n",
       "         4.65886062e-01,  -7.62140813e-01,   5.90527467e-01,\n",
       "         8.47904307e-01,  -4.85955600e-01,   4.26917893e-01,\n",
       "         2.82796182e-01,  -7.62788041e-01,  -1.41204865e-03,\n",
       "        -1.92356654e-01,  -5.17303324e-01,  -4.98349959e-01,\n",
       "        -5.74125760e-01,  -1.19979884e-01,   1.37586779e-01,\n",
       "         9.25451660e-01])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec(unique_text[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1160162346721447"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = doc2vec(unique_text[0])\n",
    "v2 = doc2vec(unique_text[200])\n",
    "np.linalg.norm(v1-v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
